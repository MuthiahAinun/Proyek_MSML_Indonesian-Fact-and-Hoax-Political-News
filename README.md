# Proyek_MSML_Indonesian-Fact-and-Hoax-Political-News

## ğŸ—‚ï¸ Dataset Description: **Indonesian Fact and Hoax Political News**

This dataset is a collection of Indonesian political news articles categorized into two main classes: Fact (valid) and Hoax (disinformation). It is sourced from both credible and non-credible platforms and is intended for training text classification models to detect fake news.

**ğŸ“ Dataset Files**

The dataset consists of the following files and their respective sources:

- `dataset_tempo_6k_cleaned.xlsx` â€“ Valid political news from Tempo (~6,000 entries)

- `dataset_kompas_4k_cleaned.xlsx` â€“ Valid political news from Kompas (~4,000 entries)

- `dataset_cnn_10k_cleaned.xlsx` â€“ Valid political news from CNN Indonesia (~10,000 entries)

- `dataset_turnbackhoax_10_cleaned.xlsx` â€“ Hoax news from Turnbackhoax.id (~10,000 entries)

**âœ… Truth Labels**

1. **Valid / Factual:** Collected from mainstream and trusted news portals: CNN Indonesia, Tempo, and Kompas.

2. **Hoax / Disinformation:** Collected from Turnbackhoax.id, a site that aggregates and verifies false or misleading claims.

**ğŸ” Dataset Source**

This dataset was downloaded from Kaggle:  
[Indonesian Fact and Hoax Political News](https://www.kaggle.com/datasets/linkgish/indonesian-fact-and-hoax-political-news?resource=download)

---
## âš™ï¸ Project Workflow Overview (GitHub Actions)

This project is designed to be built and executed using **GitHub Actions workflows**. The first step in the process is **preprocessing the four datasets**. Simply trigger the workflow defined in the `preprocess.yml` file located in `.github/workflows/`.

Once the workflow runs successfully, the **preprocessed dataset will be saved as an artifact**, which can be downloaded directly from the GitHub Actions interface.  
ğŸ“ Artifact Example:  
![Preprocessing Artifact](Experiment/preprocessing/Artifak-Preprocessing.png)

---

### ğŸ“ Project Folder Structure

```
Proyek_MSML_Indonesian-Fact-and-Hoax-Political-News
â”œâ”€â”€ .github/workflows
â”‚ â””â”€â”€ preprocess.yml # Workflow file for dataset preprocessing
â”œâ”€â”€ Experiment
â”‚ â”œâ”€â”€ dataset_raw # Folder containing original raw datasets
â”‚ â”‚ â”œâ”€â”€ dataset_cnn_10k_cleaned.xlsx
â”‚ â”‚ â”œâ”€â”€ dataset_kompas_4k_cleaned.xlsx
â”‚ â”‚ â”œâ”€â”€ dataset_tempo_6k_cleaned.xlsx
â”‚ â”‚ â””â”€â”€ dataset_turnbackhoax_10k_cleaned.xlsx
â”‚ â”œâ”€â”€ preprocessing # Folder for all preprocessing outputs
â”‚ â”‚ â”œâ”€â”€ Artifak-Preprocessing.png # Image preview of preprocessing artifact
â”‚ â”‚ â”œâ”€â”€ Eksperimen_MSML_Tsamarah_Muthiah_Abdullah.ipynb # Full notebook for preprocessing, training, and inference (Colab-based)
â”‚ â”‚ â”œâ”€â”€ automate_Tsamarah-Muthiah-Abdullah.py # Python script to automate preprocessing (used in preprocess.yml)
â”‚ â”‚ â”œâ”€â”€ dataset-cleaned.gz # Cleaned dataset exported from Colab
â”‚ â”‚ â””â”€â”€ dataset_cleaned.gz # Cleaned dataset generated automatically from GitHub workflow artifact
```
---
